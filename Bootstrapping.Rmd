---
title: "Bootstrapping"
output: github_document
---

```{r}
library(tidyverse)
library(p8105.datasets)

set.seed(1)
```


## Bootstrapping in SLR

Simulate 2 datasets, one works with linear regression, one doesn't
```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1), # mean = 1, sd = 1
    error = rnorm(n_samp, 0, 1), # mean = 0, sd = 1
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const |> 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

Look at these data
```{r}
sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "data_source") 

sim_df |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  facet_grid(~data_source) 
```

What does `lm` do for these?
```{r}
lm(y ~ x, data = sim_df_const) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

```{r}
lm(y ~ x, data = sim_df_nonconst) |> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```
Despite the very different error structures, standard errors for coefficient estimates are similar in both cases!

## Drawing one bootstrap sample

Write a function to draw bootstrap sample.
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```

Compute a linear model to each bootstrap sample.
```{r}
boot_sample(sim_df_nonconst) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm")
```


## Drawing many bootstrap samples

Draw repeated samples with replacement
```{r}
boot_straps = 
  tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, \(i) boot_sample(df = sim_df_nonconst))
  )

boot_straps
```

Quick checks to make sure this has worked as intended. 
First look at a couple of bootstrap samples.
```{r}
boot_straps |> 
  slice(1:3) |> 
  mutate(strap_sample = map(strap_sample, \(s) arrange(s, x))) |> 
  pull(strap_sample)
```
Seems okay – some values are repeated, some don’t appear in both datasets. 

Next, use ggplot to show some of these datasets, and to include a linear fit for each.
```{r}
boot_straps |> 
  slice(1:3) |> 
  unnest(strap_sample) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm", se = FALSE) +
  facet_grid(~strap_number) 
```
This shows some of the differences across bootstrap samples, and shows that the fitted regression lines aren’t the same for every bootstrap sample.



## Analyzing bootstrap samples

Finally, run analysis
```{r}
bootstrap_results = 
  boot_straps |> 
  mutate(
    models = map(strap_sample, \(df) lm(y ~ x, data = df) ),
    results = map(models, broom::tidy)) |> 
  select(-strap_sample, -models) |> 
  unnest(results) 
bootstrap_results
```

Look at results
```{r}
bootstrap_results |> 
  group_by(term) |> 
  summarize(
    boot_mean = mean(estimate),
    boot_se = sd(estimate)) |> 
  knitr::kable(digits = 3)
```
Comparing these to the results of ordinary least squares, the standard error for the intercept is much smaller (more confident to the intercept) and the standard error for the slope is a bit larger. 
This is reasonable, given the non-constant variance in the data given smaller residuals around zero and larger residuals in the the tails of the x distribution.

Use the estimates across bootstrap samples to construct a confidence interval. 
```{r}
bootstrap_results |> 
  group_by(term) |> 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))
```

For a simple linear regression, we can show the fitted lines for each bootstrap sample to build intuition for these results.
```{r}
boot_straps |> 
  unnest(strap_sample) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_line(aes(group = strap_number), stat = "smooth", method = "lm", se = FALSE, alpha = .1, color = "blue") +
  geom_point(data = sim_df_nonconst, alpha = .5)
```
In comparison to the standard error bands in our previous plot (which are based on OLS), the distribution of regression lines is narrower near x = 0 and wider at the ends of the x istribution.


## `bootstrap`

`bootstrap` function; easy to draw bootstrap samples, and stores them in a mostly-helpful way – as a `resample` object that can be converted to and treated like a data frame. 
```{r}
boot_straps = 
  sim_df_nonconst |> 
  modelr::bootstrap(n = 1000)

boot_straps |> pull(strap) |> nth(1)
```
```{r}
boot_straps |> pull(strap) |> nth(1) |> as_tibble()
```

Repeat our analysis pipeline using the bootstrap function instead of our own process for drawing samples with replacement.
```{r}
sim_df_nonconst |> 
  modelr::bootstrap(n = 1000) |> 
  mutate(
    models = map(strap, \(df) lm(y ~ x, data = df) ),
    results = map(models, broom::tidy)) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  group_by(term) |> 
  summarize(boot_se = sd(estimate))
```

To `bootstrap` the dataset with constant error variance, we only have to change the input dataframe!
```{r}
sim_df_const |> 
  modelr::bootstrap(n = 1000) |> 
  mutate(
    models = map(strap, \(df) lm(y ~ x, data = df)),
    results = map(models, broom::tidy)) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  group_by(term) |> 
  summarize(boot_se = sd(estimate))
```


## Airbnb Example

Loads and tidies the data.
```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb |> 
  mutate(stars = review_scores_location / 2) |> 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) |> 
  filter(borough != "Staten Island") |> 
  drop_na(price, stars) |> 
  select(price, stars, borough, neighborhood, room_type)
```

Quick plot showing these data, with particular emphasis on the features
`price` as an outcome with `stars` and `room_type` as covariates.
```{r}
nyc_airbnb |> 
  ggplot(aes(x = stars, y = price, color = room_type)) + 
  geom_point() 
```
In this plot, we noticed that some large outliers in price might affect estimates and inference for the association between star rating and price. Because estimates are likely to be sensitive to those outliers and “usual” rules for inference may not apply.


Uses the `bootstrap` to examine the distribution of regression coefficients under repeated sampling.
```{r}
nyc_airbnb |> 
  filter(borough == "Manhattan") |> 
  modelr::bootstrap(n = 1000) |> 
  mutate(
    models = map(strap, \(df) lm(price ~ stars + room_type, data = df)),
    results = map(models, broom::tidy)) |> 
  select(results) |> 
  unnest(results) |> 
  filter(term == "stars") |> 
  ggplot(aes(x = estimate)) + geom_density()
```

```{r}

```

```{r}

```















